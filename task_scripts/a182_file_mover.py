# -------------------------------------------------------------------------------
# Name:        fileMover
# Purpose:      Renames and sorts files into the correct locations on the server
#
# Author:      Bryan Cort
#
# Created:     10/02/2014
#-------------------------------------------------------------------------------

import os
import shutil
import glob
import fnmatch
import tarfile

from utils import file_utils
# from servertools import *

# add_tbs()

# global idMap


def mapIDs(ftable='idTable.txt'):
    """
    Looks up MRI IDs and maps them to subject IDs. All ids are stored as strings.
    Args
        ftable:     Simple table of subject and mri IDs. Subject ids go in the first column, MRI ids go in subsequent columns. No restrictions on dimensions.
    Returns
        Dict mapping MRI ID : subject ID; currently also maps subject ID : subject ID
    """
    table = file_utils.readTable2(ftable)
    idMap = {}
    for row in table:
        for entry in row:
            if entry in idMap.keys():
                continue
            idMap[str(entry)] = str(row[
                0])  #This maps subjIDs to themselves; this is important for renaming functions to work on both MRI IDs and subject IDs
    return idMap


def checkDir(dFile, targDir):
    """
    Checks for a file with the same subject, session, task, and file extension as dFile in targDir. Only meaningful for correctly named data files.
    Args
        dFile:      The file to check for
        targDir:    The directory to check in
    Returns
        True if a matching filename exists, False otherwise
    """
    fname = dFile.rsplit(os.path.sep, 1)[-1]  #should work for path names or file names with no path
    fparts = fname.rsplit('.', 1)
    fext = fparts[-1]
    tokens = fparts[0].split('_')
    subjID = tokens[0]
    session = tokens[1]
    task = tokens[2]
    fMatch = '{0}_{1}_{2}*.{3}'.format(subjID, session, task, fext)
    if glob.glob(targDir + os.path.sep + fMatch):
        return True
    return False


def tokenize(fname):
    """
    Parses a filename and returns tokens useful for reconstructing an informative filename
    Args
        fname: the filename to tokenize
    Returns
        (oldname, fext, tokens) tuple. Tokens are generated by stripping the file extension and then splitting the filename on _ and - characters.
    """
    #pull the extension off the filename and store the old name
    parts = fname.split('.', 1)
    oldname = parts[0]
    fext = parts[1]
    #Convert -'s into _'s and split the filename into tokens
    tokens = oldname.replace('-', '_').split('_')

    return (oldname, fext, tokens)


# #Functions to rename and move files for each task
# def rnbiopac(fname):
#     """
#     Renames biopac files
#     Args
#         fname: name (not full path) of the file to rename
#     Returns
#         (newname, task) tuple
#     """
#     task = 'biopac'
#
#     oldname, fext, tokens = tokenize(fname)
#
#     #get the mri or subject id
#     fID = tokens[0].strip('tb')
#     #convert it to a subject id
#     if fID in idMap.keys():
#         subjID = idMap[fID]
#     else:
#         print 'No id table match for {0}'.format(fID)
#         subjID = fID
#     #get session name from filename
#     session = tokens[1].strip('sS')
#
#     newname = '{0}_{1}_{2}_[{3}].{4}'.format(subjID, session, task, oldname, fext)
#     return (newname, task)
#
# def rnhebb(fname):
#     """
#     Renames hebb files (HaskinsHebb)
#     Args
#         fname: name (not full path) of the file to rename
#     Returns
#         (newname, task) tuple
#     """
#     task = 'hebb'
#
#     oldname, fext, tokens = tokenize(fname)
#
#     #get the mri or subject id
#     fID = tokens[1]
#     #convert it to a subject id
#     if fID in idMap.keys():
#         subjID = idMap[fID]
#     else:
#         print 'No id table match for {0}'.format(fID)
#         subjID = fID
#     #get session name from filename
#     session = tokens[2]
#
#     newname = '{0}_{1}_{2}_[{3}].{4}'.format(subjID, session, task, oldname, fext)
#     return (newname, task)
#
# def rnhebb2(fname):
#     """
#     Renames hebb2 files (LouisaHebb)
#     Args
#         fname: name (not full path) of the file to rename
#     Returns
#         (newname, task) tuple
#     """
#     task = 'hebb2'
#
#     oldname, fext, tokens = tokenize(fname)
#
#     #get the mri or subject id
#     fID = tokens[2]
#     #convert it to a subject id
#     if fID in idMap.keys():
#         subjID = idMap[fID]
#     else:
#         print 'No id table match for {0}'.format(fID)
#         subjID = fID
#     #get session name from filename
#     session = tokens[3]
#
#     newname = '{0}_{1}_{2}_[{3}].{4}'.format(subjID, session, task, oldname, fext)
#     return (newname, task)
#
# def rnSALfmri(fname):
#     """
#     Renames SALfmri files
#     Args
#         fname: name (not full path) of the file to rename
#     Returns
#         (newname, task) tuple
#     """
#     task = 'SALfmri'
#
#     oldname, fext, tokens = tokenize(fname)
#
#     #get the mri or subject id
#     fID = tokens[2]
#     #convert it to a subject id
#     if fID in idMap.keys():
#         subjID = idMap[fID]
#     else:
#         print 'No id table match for {0}'.format(fID)
#         subjID = fID
#     #get session name from filename
#     session = tokens[3]
#
#     newname = '{0}_{1}_{2}_[{3}].{4}'.format(subjID, session, task, oldname, fext)
#     return (newname, task)
#
# def rnSALtrain(fname):
#     """
#     Renames SALTrain files, except those with .edf or .EDF extensions; these are saved with a different naming pattern
#     Args
#         fname: name (not full path) of the file to rename
#     Returns
#         (newname, task) tuple
#     """
#     task = 'SALtrain'
#
#     oldname, fext, tokens = tokenize(fname)
#
#     #get the mri or subject id
#     fID = tokens[2]
#     #convert it to a subject id
#     if fID in idMap.keys():
#         subjID = idMap[fID]
#     else:
#         print 'No id table match for {0}'.format(fID)
#         subjID = fID
#     #get session name from filename
#     session = tokens[3]
#
#     newname = '{0}_{1}_{2}_[{3}].{4}'.format(subjID, session, task, oldname, fext)
#     return (newname, task)
#
# def rnSALtrainEDF(fname):
#     """
#     Renames SALTrain files with .edf or .EDF extensions (eyetracker files)
#     Args
#         fname: name (not full path) of the file to rename
#     Returns
#         (newname, task) tuple
#     """
#     task = 'SALtrain'
#
#     oldname, fext, tokens = tokenize(fname)
#
#     #get the mri or subject id
#     fID = tokens[0]
#     #convert it to a subject id
#     if fID in idMap.keys():
#         subjID = idMap[fID]
#     else:
#         print 'No id table match for {0}'.format(fID)
#         subjID = fID
#     #get session name from filename
#     session = tokens[1]
#
#     newname = '{0}_{1}_{2}_[{3}].{4}'.format(subjID, session, task, oldname, fext)
#     return (newname, task)
#
# def rnSCC(fname):
#     """
#     Renames SCC files
#     Args
#         fname: name (not full path) of the file to rename
#     Returns
#         (newname, task) tuple
#     """
#     task = 'SCC'
#
#     oldname, fext, tokens = tokenize(fname)
#
#     #get the mri or subject id
#     fID = tokens[0].lstrip('CC').rstrip('dat')
#     #convert it to a subject id
#     if fID in idMap.keys():
#         subjID = idMap[fID]
#     else:
#         print 'No id table match for {0}'.format(fID)
#         subjID = fID
#     #get session name from filename
#     session = 1
#
#     newname = '{0}_{1}_{2}_[{3}].{4}'.format(subjID, session, task, oldname, fext)
#     return (newname, task)
#
# def rnSRTT(fname):
#     """
#     Renames SRTT files
#     Args
#         fname: name (not full path) of the file to rename
#     Returns
#         (newname, task) tuple
#     """
#     task = 'SRTT'
#
#     oldname, fext, tokens = tokenize(fname)
#
#     #get the mri or subject id
#     fID = tokens[1]
#     #convert it to a subject id
#     if fID in idMap.keys():
#         subjID = idMap[fID]
#     else:
#         print 'No id table match for {0}'.format(fID)
#         subjID = fID
#     #get session name from filename
#     session = tokens[2]
#
#     newname = '{0}_{1}_{2}_[{3}].{4}'.format(subjID, session, task, oldname, fext)
#     return (newname, task)
#
# def rnstopsignal(fname):
#     """
#     Renames stopsignal files
#     Args
#         fname: name (not full path) of the file to rename
#     Returns
#         (newname, task) tuple
#     """
#     task = 'stopsignal'
#
#     oldname, fext, tokens = tokenize(fname)
#
#     #get the mri or subject id
#     fID = tokens[0].strip('st')
#     #convert it to a subject id
#     if fID in idMap.keys():
#         subjID = idMap[fID]
#     else:
#         print 'No id table match for {0}'.format(fID)
#         subjID = fID
#     #get session name from filename
#     session = 1
#
#     newname = '{0}_{1}_{2}_[{3}].{4}'.format(subjID, session, task, oldname, fext)
#     return (newname, task)
#
# def rnstrain(fname):
#     """
#     Renames strain files
#     Args
#         fname: name (not full path) of the file to rename
#     Returns
#         (newname, task) tuple
#     """
#     task = 'strain'
#
#     oldname, fext, tokens = tokenize(fname)
#
#     #get the mri or subject id
#     fID = tokens[0]
#     #convert it to a subject id
#     if fID in idMap.keys():
#         subjID = idMap[fID]
#     else:
#         print 'No id table match for {0}'.format(fID)
#         subjID = fID
#     #get session name from filename
#     session = 1
#
#     newname = '{0}_{1}_{2}_[{3}].{4}'.format(subjID, session, task, oldname, fext)
#     return (newname, task)
#
# def rnVAL3train(fname):
#     """
#     Renames VAL3Train files
#     Args
#         fname: name (not full path) of the file to rename
#     Returns
#         (newname, task) tuple
#     """
#     task = 'VAL3train'
#
#     oldname, fext, tokens = tokenize(fname)
#
#     #get the mri or subject id
#     fID = tokens[2]
#     #convert it to a subject id
#     if fID in idMap.keys():
#         subjID = idMap[fID]
#     else:
#         print 'No id table match for {0}'.format(fID)
#         subjID = fID
#     #get session name from filename
#     session = tokens[3]
#
#     newname = '{0}_{1}_{2}_[{3}].{4}'.format(subjID, session, task, oldname, fext)
#     return (newname, task)
#
# def rnVAL3fmri(fname):
#     """
#     Renames VAL3Train files
#     Args
#         fname: name (not full path) of the file to rename
#     Returns
#         (newname, task) tuple
#     """
#     task = 'VAL3fmri'
#
#     oldname, fext, tokens = tokenize(fname)
#
#     #get the mri or subject id
#     fID = tokens[2]
#     #convert it to a subject id
#     if fID in idMap.keys():
#         subjID = idMap[fID]
#     else:
#         print 'No id table match for {0}'.format(fID)
#         subjID = fID
#     #get session name from filename
#     session = tokens[3]
#
#     newname = '{0}_{1}_{2}_[{3}].{4}'.format(subjID, session, task, oldname, fext)
#     return (newname, task)
#
# def rnzeo(fname):
#     """
#     Renames zeo files
#     Args
#         fname: name (not full path) of the file to rename
#     Returns
#         (newname, task) tuple
#     """
#     task = 'zeo'
#
#     oldname, fext, tokens = tokenize(fname)
#
#     #get the mri or subject id
#     fID = tokens[0]
#     #convert it to a subject id
#     if fID in idMap.keys():
#         subjID = idMap[fID]
#     else:
#         print 'No id table match for {0}'.format(fID)
#         subjID = fID
#     #get session name from filename
#     session = 1
#
#     newname = '{0}_{1}_{2}_[{3}].{4}'.format(subjID, session, task, oldname, fext)
#     return (newname, task)

def tarStrain(d):
    """
    Looks for strain recordings for each participant and compresses them into a single .tar.gz
    Args
        d: Directory to look for strain recordings in
    """
    #find all the strain recordings
    strainRecs = glob.glob(os.path.join(d, '*StrainNaming*.wav'))
    recMap = {}
    for rec in strainRecs:
        recMap[rec] = rec.rsplit(os.path.sep, 1)[-1]  #pathname:filename
    #get all the unique ids
    ids = set()
    for f in recMap.values():
        ids.add(f[:4])  #TODO: improve this with actual regex/pattern matching later
    #check for existing archives for each id
    for n in ids:
        if not glob.glob(os.path.join(d, '{0}_?_strain*.tar.gz'.format(n))):
            #tar.gz all files for each id without an archive
            with tarfile.open(os.path.join(d, '{0}_Strain_Recordings.tar.gz'.format(n)), 'w:gz') as tar:
                for f in glob.glob(os.path.join(d, '{0}*StrainNaming*.wav'.format(n))):
                    tar.add(f, arcname=f.rsplit(os.path.sep, 1)[-1])


# TODO: Add tar.gz'ing for hebb2 if needed
def tarHebb(d):
    """
    Looks for hebb recordings for each participant and compresses them into a single .tar.gz
    Args
        d: Directory to look for hebb recordings in
    """
    #find all the hebb recordings
    hebbRecs = glob.glob(os.path.join(d, '[0-9][0-9][0-9][0-9]*[Hh][Ee][Bb][Bb]*.[wm][ap][v3]'))
    recMap = {}
    for rec in hebbRecs:
        recMap[rec] = rec.rsplit(os.path.sep, 1)[-1]  #pathname:filename
    #get all the unique ids
    ids = set()
    for f in recMap.values():
        ids.add(f[:4])  # TODO: improve this with actual regex/pattern matching later
    for n in ids:
        #check for existing archives for each id
        if not glob.glob(os.path.join(d, '*Hebb_{0}_?_hebb*.tar.gz'.format(n))):
            #tar.gz all files for each id without an archive
            with tarfile.open(os.path.join(d, 'HaskinsHebb-{0}-T.tar.gz'.format(n)), 'w:gz') as tar:
                for f in glob.glob(os.path.join(d, '{0}*[Hh][Ee][Bb][Bb]*.[wm][ap][v3]'.format(n))):
                    tar.add(f, arcname=f.rsplit(os.path.sep, 1)[-1])


def _id_filter(tokens, filters):
    """
    applies each filter to each token; if filter[0] matches a token, take the filter[1]:filter[2] substring of token and
    return it if it is the only match

    :param tokens: list of tokens to filter
    :param filters: filter triplets (pattern, start, stop) to apply
    :returns match: single token matching and filtered by a single filter,
    """
    _match = []
    for token in tokens:
        for pair in filters:
            if fnmatch.fnmatch(token, pair[0]):
                _match.append(token[pair[1]:pair[2]])
    match = _match.pop()
    if not match:
        return 0
    if _match:
        return None
        # raise Exception("More than one match in {} for filters {}".format(tokens, filters))
    return match


# def _rename(old_name, ):
#     pass


def main():
    dry_run = True

    #directory paths
    # todo: replace this with an argument parser and useful defaults
    base_dir = os.path.normpath("/data1/A182/A182BehavioralData")

    os.chdir(base_dir)

    transferDir = os.path.normpath("TRANSFER")
    rawdataDir = os.path.normpath("RAWDATA")
    dataDir = os.path.normpath("DATA")

    idMap = mapIDs()
    #fname pattern : function map
    pmap = {"tb????[-_]*.*": 'biopac',
            "*HaskinsHebb[-_]*[-_]*.[et][dxa][atr]*": 'hebb',
            "*HebbLouisa*.[et][dxa][atr]*": 'hebb2',
            "*ALL_fMRI[-_]*[-_]*.*": 'SALfmri',
            "*ArtLex_A182ET[-_]*[-_]*.*": 'SALtrain',
            "[0-9][0-9][0-9][0-9][-_][0-9].[eE][dD][fF]": 'SALtrain',
            "*CC[0-9][0-9][0-9]*dat.*": 'SCC',
            "*SRT2[-_]*[-_]*.*": 'SRTT',
            "st[0-9][0-9][0-9][0-9].*": 'stopsignal',
            "*[-_]Strain*.[tcl][xsao][tvrg]*": 'strain',  #covers txt, csv, log, .tar.gz files
            "A182Exp2[-_]VAL3[-_]*[-_]*.*": 'VAL3train',
            "????[-_][ABC].[tdcD][xasA][tvT]": 'zeo',  #covers txt, dat, and csv files
            "*VAL_fMRI[-_]*[-_]*.*": 'VAL3fmri'
    }

    id_filters = (('tb[0-9][0-9][0-9][0-9]', None, None),
                  ('[0-9][0-9][0-9][0-9]', None, None),
                  ('CC[0-9][0-9][0-9][0-9]dat', 2, 6),
                  ('st[0-9][0-9][0-9][0-9]', 2, None))

    session_filters = (('s[0-9]', 1, None),
                       ('[0-9]', None, None))

    #read in all the files and map full path name : filename
    transfer_files = []
    for triple in os.walk(transferDir):
        #tar.gz any hebb recordings
        tarHebb(triple[0])
        #tar.gz any strain recordings
        tarStrain(triple[0])
        #get a simple list of all the file paths
        transfer_files.append(glob.glob(os.path.join(triple[0], '*.*')))

    moved_raw = []
    moved_data = []
    duplicate_raw = []
    duplicate_data = []
    unmatched_files = []
    no_id_files = []

    for transfer_file in transfer_files:
        try:
            task = None
            transfer_file_name = os.path.split(transfer_file)
            for pattern in pmap:
                if fnmatch.fnmatch(transfer_file_name, pattern):
                    task = pmap[pattern]
            if task:
                transfer_file_name_noext, transfer_file_ext, transfer_file_tokens = tokenize(transfer_file_name)
                scan_id = _id_filter(transfer_file_tokens, id_filters)
                try:
                    subj_id = idMap[scan_id]
                except KeyError:
                    print "No subject ID mapped to {}; {} not moved".format(scan_id, transfer_file)
                    break
                session_id = _id_filter(transfer_file_tokens, session_filters)
                if session_id == 0:
                    session_id= 1
                if session_id == None:
                    print "Warning: multiple session ID matches for {}".format(transfer_file)
                new_file_name = "{}_{}_{}_[{}].{}".format(subj_id, session_id, task, transfer_file_name_noext,
                                                          transfer_file_ext)

                if not checkDir(new_file_name, rawdataDir):
                    new_file_path = os.path.join(rawdataDir, new_file_name)
                    if not dry_run:
                        shutil.copy(transfer_file, new_file_path)
                    moved_raw.append("{} --> {}".format(transfer_file, new_file_path))
                    # rawlog.write('{0}\n'.format(fkey))
                    # rawMoved += 1
                else:
                    duplicate_raw.append(transfer_file)
                if not checkDir(new_file_name, os.path.join(dataDir, task)):
                    new_file_path = os.path.join(dataDir, task, new_file_name)
                    if not dry_run:
                        shutil.copy(transfer_file, new_file_path)
                    moved_data.append("{} --> {}".format(transfer_file, new_file_path))
                    # datalog.write('{0}\n'.format(fkey))
                    # dataMoved += 1
                else:
                    duplicate_data.append(transfer_file)
            else:
                unmatched_files += 1
        except:
            print "Unhandled exception while processing {}".format(transfer_file)
            raise
        finally:
            with open('rawdataTransferLog.txt', 'w') as rawlog:
                rawlog.write("\n".join(moved_raw))
            with open('dataTransferLog.txt', 'w') as datalog:
                datalog.write("\n".join(moved_data))
            with open('rawdataTransferLog.txt', 'w') as unmatchedlog:
                unmatchedlog.write("\n".join(moved_raw))
            with open('rawdataTransferLog.txt', 'w') as no_id_log:
                no_id_log.write("\n".join(moved_raw))
            print '{} files moved to {}'.format(len(moved_raw), rawdataDir)
            print '{} files moved to {}'.format(len(moved_data), dataDir)
            print '{} duplicate files not moved to {}'.format(len(duplicate_raw), rawdataDir)
            print '{} duplicate files not moved to {}'.format(len(duplicate_data), dataDir)
            print '{} files could not be matched to a task'.format(len(no_id_files))
            print '{} files could not be matched to an ID'.format(len(unmatched_files))


    # #map of {oldPath : [oldname, newname, path]}
    # fmap = {}
    # for flist in transfer_files:
    #     for f in flist:
    #         if f:
    #             fn = f.rsplit(os.path.sep, 1)[1]
    #             fmap[f] = [fn]  #preparing to make this {path: [oldname, newname]}
    # #counts of how many files went to each dir
    # rawMoved = 0
    # dataMoved = 0
    # rawDup = 0
    # dataDup = 0
    # #get the new filenames for each file
    # with open('rawdataTransferLog.txt', 'w') as rawlog, open('dataTransferLog.txt', 'w') as datalog:
    #     rawlog.write('FILES TRANSFERED TO RAWDATA\n')
    #     datalog.write('FILES TRANSFERED TO DATA\n')
    #     for fkey in fmap.keys():
    #         f = fmap[fkey]
    #         fpatt = []
    #         for pattern in pmap:
    #             if fnmatch.fnmatch(f[0], pattern):
    #                 fpatt.append(pattern)
    #         #only copy the file if we got a pattern match
    #         if fpatt:
    #             p = fpatt.pop()
    #             if fpatt:
    #                 raise Exception("More than one pattern match for {0}".format(f))
    #             try:
    #                 f.extend(pmap[p](f[0]))
    #             except:
    #                 print 'Failed to rename {0}'.format(f[0])
    #                 raise
    #             try:
    #                 #copy the files that don't yet exist in DATA or RAWDATA to those directories
    #                 if not checkDir(f[1], rawdataDir):
    #                     shutil.copy(fkey, os.path.join(rawdataDir, f[1]))
    #                     rawlog.write('{0}\n'.format(fkey))
    #                     rawMoved += 1
    #                 else:
    #                     rawDup += 1
    #                 if not checkDir(f[1], os.path.join(dataDir, f[2])):
    #                     shutil.copy(fkey, os.path.join(dataDir, f[2], f[1]))
    #                     datalog.write('{0}\n'.format(fkey))
    #                     dataMoved += 1
    #                 else:
    #                     dataDup += 1
    #             except:
    #                 print 'Error for {0}'.format(fkey)
    #     print 'Moved {} files to {}'.format(rawMoved, rawdataDir)
    #     print 'Moved {} files to {}'.format(dataMoved, dataDir)
    #     print '{} duplicate files not moved to {}'.format(rawDup, rawdataDir)
    #     print '{} duplicate files not moved to {}'.format(dataDup, dataDir)


if __name__ == '__main__':
    main()
